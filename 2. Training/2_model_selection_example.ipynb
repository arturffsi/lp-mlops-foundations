{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52edf4a",
   "metadata": {},
   "source": [
    "# üîé Model Selection (CatBoost + Comparators)\n",
    "\n",
    "**Purpose:** Build a *stable*, **reproducible**, and **config-driven** model selection notebook that is safe to promote toward production.\n",
    "\n",
    "> This notebook runs on SageMaker or locally. It loads prepared features (e.g., from **Redshift**, **Postgres**, or **S3 Parquet** via `data_io.py`),\n",
    "applies deterministic splits, trains a small **model zoo** (CatBoost baseline + LightGBM + XGBoost + Logistic Regression), and\n",
    "selects the **best model by Recall** (with a target recall threshold), using PR-AUC and ROC-AUC as tie-breakers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271b2c2",
   "metadata": {},
   "source": [
    "## üì¶ What You Get\n",
    "- Config-first data loader (`data_io.load_data()` if present; fallback to **SQL** via SQLAlchemy or **synthetic demo**)  \n",
    "- Cleaning & minimal feature handling (categoricals + datetime)  \n",
    "- **Leakage-aware**, deterministic **time split** (or stratified split)  \n",
    "- **Model zoo**: CatBoost (baseline), LightGBM, XGBoost, Logistic Regression  \n",
    "- **Threshold tuning** for target recall (e.g., 80%) and comparison table  \n",
    "- Export **artifacts**: `model.(cbm|json)`, `metrics.json`, `thresholds.json`  \n",
    "- Optional **MLflow** run logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c57a3",
   "metadata": {},
   "source": [
    "## üß∞ Prerequisites\n",
    "- Python 3.9+\n",
    "- Packages: `pandas`, `numpy`, `pyarrow`, `scikit-learn`, `catboost`, `lightgbm`, `xgboost`, `sqlalchemy`, `redshift_connector`, `s3fs`, `mlflow` (optional)\n",
    "- Optional: a `data_io.py` next to this notebook with a `load_data(...)` API.\n",
    "\n",
    "```python\n",
    "# If running on a fresh environment (SageMaker usually has most of these):\n",
    "# %pip install pandas numpy pyarrow scikit-learn catboost lightgbm xgboost mlflow sqlalchemy redshift_connector s3fs\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a971422",
   "metadata": {},
   "source": [
    "## ‚ôªÔ∏è Reproducibility & Environment Capture\n",
    "- **Fixed seeds** for determinism\n",
    "- Save **package versions** and run metadata\n",
    "- Unique **artifact run folder**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703293aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, hashlib, platform, random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RUN_TS = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "RUN_ID = hashlib.sha1(f\"{RUN_TS}-{SEED}\".encode()).hexdigest()[:10]\n",
    "\n",
    "ARTIFACT_DIR = os.environ.get(\"ARTIFACT_DIR\", f\"artifacts/run_{RUN_TS}_{RUN_ID}\")\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "env_info = {\n",
    "    \"python\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"timestamp_utc\": RUN_TS,\n",
    "    \"seed\": SEED,\n",
    "    \"packages\": {\n",
    "        \"pandas\": pd.__version__,\n",
    "        \"numpy\": np.__version__,\n",
    "    },\n",
    "}\n",
    "with open(os.path.join(ARTIFACT_DIR, \"env_info.json\"), \"w\") as f:\n",
    "    json.dump(env_info, f, indent=2)\n",
    "env_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13119ecc",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "Edit **only here** to switch sources and behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9302098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIG = {\n",
    "    \"data\": {\n",
    "        # choose one of: 'redshift' | 'parquet' | 'postgres' | 'synthetic'\n",
    "        \"source\": os.environ.get(\"SOURCE\", \"postgres\"),\n",
    "        \"parquet_uri\": os.environ.get(\"PARQUET_URI\", \"s3://your-bucket/path/to/data/*.parquet\"),\n",
    "        \"sql\": os.environ.get(\"SQL\", \"SELECT * FROM public.final_feature_snapshot\"),\n",
    "        # Redshift\n",
    "        \"redshift_kwargs\": {\n",
    "            \"host\": os.environ.get(\"REDSHIFT_HOST\", \"example.redshift.amazonaws.com\"),\n",
    "            \"database\": os.environ.get(\"REDSHIFT_DB\", \"dev\"),\n",
    "            \"user\": os.environ.get(\"REDSHIFT_USER\", \"username\"),\n",
    "            \"password\": os.environ.get(\"REDSHIFT_PASSWORD\", \"password\"),\n",
    "            \"port\": int(os.environ.get(\"REDSHIFT_PORT\", \"5439\")),\n",
    "        },\n",
    "        # Postgres (psycopg3, SQLAlchemy URL)\n",
    "        \"pg\": {\n",
    "            \"user\": os.getenv(\"PGUSER\", \"postgres\"),\n",
    "            \"password\": os.getenv(\"PGPASSWORD\", \"postgres\"),\n",
    "            \"host\": os.getenv(\"PGHOST\", \"localhost\"),\n",
    "            \"port\": os.getenv(\"PGPORT\", \"5432\"),\n",
    "            \"db\": os.getenv(\"PGDATABASE\", \"testdb\"),\n",
    "        },\n",
    "        \"row_limit\": int(os.environ.get(\"ROW_LIMIT\", \"0\")) or None,\n",
    "    },\n",
    "    \"columns\": {\n",
    "        \"target\": os.environ.get(\"TARGET\", \"churn\"),\n",
    "        \"primary_key\": os.environ.get(\"PRIMARY_KEY\", \"codigocontaservico\"),\n",
    "        # date column for time-based split (falls back to stratified)\n",
    "        \"time_col\": os.environ.get(\"TIME_COL\", \"iddim_date_inicio\"),\n",
    "        # columns known to be leakage or pure identifiers\n",
    "        \"drop_cols\": [\n",
    "            \"idconsumo\",\"id_contaservico\",\"codigocontaservico\",\"idconta\",\"iddim_cliente\",\n",
    "            \"idcliente\",\"codigocliente\",\"iddim_conta\",\"codigoconta\",\n",
    "            \"idgrupo_dim_contadimensao\",\"iddim_contaservico_dth\",\"idcontaservico\"\n",
    "        ],\n",
    "    },\n",
    "    \"split\": {\n",
    "        \"test_size\": 0.2,\n",
    "        \"val_size\": 0.1,  # not used by the model zoo (we‚Äôll use train/valid split only)\n",
    "        \"recall_target\": float(os.environ.get(\"RECALL_TARGET\", \"0.80\")),\n",
    "        \"stratify\": True,\n",
    "    },\n",
    "    \"models\": {\n",
    "        \"catboost\": {\"iterations\": 2000, \"early_stopping_rounds\": 200, \"depth\": 6, \"learning_rate\": 0.08, \"l2_leaf_reg\": 3.0, \"task_type\": os.environ.get(\"CAT_TASK_TYPE\", \"CPU\"), \"auto_class_weights\": \"Balanced\", \"verbose\": 200},\n",
    "        \"lightgbm\": {\"n_estimators\": 2000, \"learning_rate\": 0.05, \"num_leaves\": 64, \"min_child_samples\": 40, \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"reg_lambda\": 1.0, \"random_state\": SEED},\n",
    "        \"xgboost\":  {\"n_estimators\": 2000, \"learning_rate\": 0.05, \"max_depth\": 6, \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"reg_lambda\": 1.0, \"random_state\": SEED, \"eval_metric\": \"auc\"},\n",
    "        \"logreg\":   {\"max_iter\": 1000, \"class_weight\": \"balanced\", \"solver\": \"liblinear\", \"random_state\": SEED},\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"artifact_dir\": ARTIFACT_DIR,\n",
    "        \"processed_parquet_path\": str(Path(ARTIFACT_DIR) / \"processed\" / \"dataset.parquet\"),\n",
    "        \"metrics_path\": str(Path(ARTIFACT_DIR) / \"metrics.json\"),\n",
    "        \"thresholds_path\": str(Path(ARTIFACT_DIR) / \"thresholds.json\"),\n",
    "        \"model_dir\": str(Path(ARTIFACT_DIR) / \"models\"),\n",
    "    },\n",
    "    \"mlflow\": {\n",
    "        \"enabled\": False,\n",
    "        \"tracking_uri\": os.environ.get(\"MLFLOW_TRACKING_URI\", \"\"),\n",
    "        \"experiment_name\": os.environ.get(\"MLFLOW_EXPERIMENT\", \"model-selection\"),\n",
    "    },\n",
    "}\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1feaed6",
   "metadata": {},
   "source": [
    "## üì• Load Data\n",
    "Attempts `data_io.load_data(...)` first. If not present, uses **Postgres** (from `CONFIG['data']['pg']` and `CONFIG['data']['sql']`).\n",
    "If neither works, falls back to a **synthetic** churn-like dataset so the rest is testable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = None\n",
    "try:\n",
    "    from data_io import load_data  # optional helper\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è data_io.load_data not available:\", repr(e))\n",
    "\n",
    "def _demo_dataset(n=20000, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df = pd.DataFrame({\n",
    "        \"codigocontaservico\": np.arange(1, n+1),\n",
    "        \"iddim_date_inicio\": pd.to_datetime(\"2023-01-01\") + pd.to_timedelta(rng.integers(0, 650, size=n), unit=\"D\"),\n",
    "        \"tenure_days\": rng.integers(30, 800, size=n),\n",
    "        \"expiry_month\": rng.integers(1, 13, size=n),\n",
    "        \"expiry_dow\": rng.integers(0, 7, size=n),\n",
    "        \"tipo_produto_atual\": rng.choice([\"normal\",\"premium\"], size=n, p=[0.85,0.15]),\n",
    "        \"topup_total_value\": rng.gamma(2.0, 30.0, size=n).round(2),\n",
    "        \"municipio\": rng.choice([\"luanda\",\"lubango\",\"viana\"], size=n),\n",
    "        \"past_churns\": rng.poisson(0.2, size=n),\n",
    "        \"n_prev_contracts\": rng.integers(0, 5, size=n),\n",
    "        \"target_proxy\": rng.normal(0,1,size=n)\n",
    "    })\n",
    "    logits = -1.2 + 0.003*(df[\"tenure_days\"]) + 0.4*(df[\"tipo_produto_atual\"]==\"premium\").astype(int) - 0.0008*df[\"topup_total_value\"] + 0.35*df[\"past_churns\"]\n",
    "    p = 1/(1+np.exp(-logits))\n",
    "    df[\"churn\"] = (rng.random(size=n) < p).astype(int)\n",
    "    return df\n",
    "\n",
    "source = CONFIG[\"data\"][\"source\"].lower()\n",
    "df_raw = None\n",
    "\n",
    "try:\n",
    "    if load_data is not None:\n",
    "        print(f\"Loading via data_io.load_data(source={source}) ‚Ä¶\")\n",
    "        df_raw = load_data(\n",
    "            source=source,\n",
    "            uri=CONFIG[\"data\"][\"parquet_uri\"],\n",
    "            sql=CONFIG[\"data\"][\"sql\"],\n",
    "            redshift_kwargs=CONFIG[\"data\"][\"redshift_kwargs\"],\n",
    "        )\n",
    "    elif source == \"postgres\":\n",
    "        from sqlalchemy import create_engine, text\n",
    "        pg = CONFIG[\"data\"][\"pg\"]\n",
    "        url = f\"postgresql+psycopg://{pg['user']}:{pg['password']}@{pg['host']}:{pg['port']}/{pg['db']}\"\n",
    "        engine = create_engine(url)\n",
    "        with engine.begin() as conn:\n",
    "            df_raw = pd.read_sql_query(text(CONFIG[\"data\"][\"sql\"]), conn)\n",
    "            \n",
    "    if df_raw is None:\n",
    "        print(\"Using synthetic demo dataset ‚Ä¶\")\n",
    "        df_raw = _demo_dataset()\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Failed to load from configured source:\", repr(e))\n",
    "    print(\"Using synthetic demo dataset ‚Ä¶\")\n",
    "    df_raw = _demo_dataset()\n",
    "\n",
    "row_limit = CONFIG[\"data\"][\"row_limit\"]\n",
    "if row_limit and len(df_raw) > row_limit:\n",
    "    pk = CONFIG[\"columns\"][\"primary_key\"]\n",
    "    if pk in df_raw.columns:\n",
    "        df_raw = df_raw.sort_values(pk).head(row_limit).reset_index(drop=True)\n",
    "    else:\n",
    "        df_raw = df_raw.sample(n=row_limit, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "df_raw.head(3), df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e3b7c",
   "metadata": {},
   "source": [
    "## üîé Quick Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"column\": df_raw.columns,\n",
    "    \"dtype\": df_raw.dtypes.astype(str).values,\n",
    "    \"nulls\": [df_raw[c].isna().sum() for c in df_raw.columns],\n",
    "    \"non_nulls\": [df_raw[c].notna().sum() for c in df_raw.columns],\n",
    "}).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf9f5e",
   "metadata": {},
   "source": [
    "## üßº Minimal Cleaning & Feature Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = CONFIG[\"columns\"][\"target\"]\n",
    "primary_key = CONFIG[\"columns\"][\"primary_key\"]\n",
    "time_col = CONFIG[\"columns\"][\"time_col\"]\n",
    "drop_cols = list(set(CONFIG[\"columns\"][\"drop_cols\"] + [target_col]))\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Convert pandas timedeltas (if any) to days\n",
    "for c in df.columns:\n",
    "    if str(df[c].dtype).startswith(\"timedelta\"):\n",
    "        df[c] = df[c].dt.total_seconds() / 86400\n",
    "\n",
    "# Ensure time column is datetime if present\n",
    "if time_col in df.columns:\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "\n",
    "# Basic NaN handling for categoricals\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == \"object\" or str(df[c].dtype) == \"category\"]\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(object).where(~pd.isna(df[c]), \"<MISSING>\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e81f92",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Deterministic Split (Time-based preferred, else stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "y = df[target_col].astype(int).values if target_col in df.columns else None\n",
    "X = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "def build_split_masks(df, y, time_col):\n",
    "    if time_col in df.columns:\n",
    "        dates = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "        if dates.notna().mean() > 0.8:\n",
    "            cutoff = dates.quantile(0.8)\n",
    "            print(\"cutoff_date:\", cutoff)\n",
    "            train_mask = dates < cutoff\n",
    "            valid_mask = ~train_mask\n",
    "            return train_mask, valid_mask\n",
    "    # fallback: stratified split\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=CONFIG['split']['test_size'], random_state=SEED)\n",
    "    train_idx, valid_idx = next(splitter.split(X, y))\n",
    "    train_mask = pd.Series(False, index=X.index); train_mask.iloc[train_idx] = True\n",
    "    valid_mask = ~train_mask\n",
    "    return train_mask, valid_mask\n",
    "\n",
    "train_mask, valid_mask = build_split_masks(df, y, time_col)\n",
    "sum(train_mask), sum(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc1d34",
   "metadata": {},
   "source": [
    "## ü§ñ Model Zoo & Recall-First Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41035f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, classification_report, confusion_matrix\n",
    "\n",
    "def best_f1_threshold(y_true, y_scores):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_scores)\n",
    "    f1 = (2 * prec[:-1] * rec[:-1]) / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "    i = int(np.argmax(f1))\n",
    "    return float(thr[i]), float(f1[i]), float(prec[i]), float(rec[i])\n",
    "\n",
    "def recall_target_threshold(y_true, y_scores, target=0.80):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_scores)\n",
    "    idx = np.where(rec[:-1] >= target)[0]\n",
    "    if len(idx):\n",
    "        i = int(idx[-1])  # highest threshold with >= target recall\n",
    "        return float(thr[i]), float(prec[i]), float(rec[i])\n",
    "    return 0.0, float(prec[0]), float(rec[0])\n",
    "\n",
    "def prep_data_for_tree_models(X):\n",
    "    # Drop datetime columns; convert categoricals to string (CatBoost can handle strings directly)\n",
    "    X2 = X.copy()\n",
    "    dt_cols = [c for c in X2.columns if np.issubdtype(X2[c].dtype, np.datetime64)]\n",
    "    if dt_cols:\n",
    "        X2 = X2.drop(columns=dt_cols)\n",
    "    for c in X2.columns:\n",
    "        if X2[c].dtype == \"object\" or str(X2[c].dtype) == \"category\":\n",
    "            X2[c] = X2[c].astype(str)\n",
    "    return X2\n",
    "\n",
    "X2 = prep_data_for_tree_models(X)\n",
    "X_train, X_valid = X2.loc[train_mask], X2.loc[valid_mask]\n",
    "y_train, y_valid = y[train_mask], y[valid_mask]\n",
    "\n",
    "results = []\n",
    "thresholds = {}\n",
    "model_objects = {}\n",
    "\n",
    "# --- CatBoost ---\n",
    "try:\n",
    "    from catboost import CatBoostClassifier, Pool\n",
    "    cat_cols = [c for c in X_train.columns if X_train[c].dtype == 'object']\n",
    "    cat_idx = X_train.columns.get_indexer(cat_cols).tolist()\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_idx)\n",
    "    valid_pool = Pool(X_valid, y_valid, cat_features=cat_idx)\n",
    "    params = CONFIG['models']['catboost']\n",
    "    cb = CatBoostClassifier(\n",
    "        iterations=params['iterations'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        depth=params['depth'],\n",
    "        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=SEED,\n",
    "        auto_class_weights=params.get('auto_class_weights','Balanced'),\n",
    "        task_type=params.get('task_type','CPU'),\n",
    "        verbose=params.get('verbose', 200)\n",
    "    )\n",
    "    cb.fit(train_pool, eval_set=valid_pool, use_best_model=True, early_stopping_rounds=params['early_stopping_rounds'])\n",
    "    valid_proba = cb.predict_proba(valid_pool)[:,1]\n",
    "    roc = roc_auc_score(y_valid, valid_proba)\n",
    "    pr = average_precision_score(y_valid, valid_proba)\n",
    "    thr_f1, best_f1, p_f1, r_f1 = best_f1_threshold(y_valid, valid_proba)\n",
    "    thr_rec, p80, r80 = recall_target_threshold(y_valid, valid_proba, CONFIG['split']['recall_target'])\n",
    "    results.append({\"model\":\"catboost\",\"roc_auc\":roc,\"pr_auc\":pr,\"best_f1\":best_f1,\"precision_at_best_f1\":p_f1,\"recall_at_best_f1\":r_f1,\"precision_at_recall_target\":p80,\"recall_at_recall_target\":r80})\n",
    "    thresholds['catboost'] = {\"best_f1_threshold\":thr_f1, \"recall_target_threshold\":thr_rec}\n",
    "    model_objects['catboost'] = cb\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è CatBoost unavailable:\", repr(e))\n",
    "\n",
    "# --- LightGBM ---\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    lgbm = lgb.LGBMClassifier(**CONFIG['models']['lightgbm'])\n",
    "    lgbm.fit(X_train, y_train, eval_set=[(X_valid,y_valid)], eval_metric='auc', verbose=False)\n",
    "    valid_proba = lgbm.predict_proba(X_valid)[:,1]\n",
    "    roc = roc_auc_score(y_valid, valid_proba)\n",
    "    pr = average_precision_score(y_valid, valid_proba)\n",
    "    thr_f1, best_f1, p_f1, r_f1 = best_f1_threshold(y_valid, valid_proba)\n",
    "    thr_rec, p80, r80 = recall_target_threshold(y_valid, valid_proba, CONFIG['split']['recall_target'])\n",
    "    results.append({\"model\":\"lightgbm\",\"roc_auc\":roc,\"pr_auc\":pr,\"best_f1\":best_f1,\"precision_at_best_f1\":p_f1,\"recall_at_best_f1\":r_f1,\"precision_at_recall_target\":p80,\"recall_at_recall_target\":r80})\n",
    "    thresholds['lightgbm'] = {\"best_f1_threshold\":thr_f1, \"recall_target_threshold\":thr_rec}\n",
    "    model_objects['lightgbm'] = lgbm\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è LightGBM unavailable:\", repr(e))\n",
    "\n",
    "# --- XGBoost ---\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb = XGBClassifier(**CONFIG['models']['xgboost'])\n",
    "    xgb.fit(X_train, y_train, eval_set=[(X_valid,y_valid)], verbose=False)\n",
    "    valid_proba = xgb.predict_proba(X_valid)[:,1]\n",
    "    roc = roc_auc_score(y_valid, valid_proba)\n",
    "    pr = average_precision_score(y_valid, valid_proba)\n",
    "    thr_f1, best_f1, p_f1, r_f1 = best_f1_threshold(y_valid, valid_proba)\n",
    "    thr_rec, p80, r80 = recall_target_threshold(y_valid, valid_proba, CONFIG['split']['recall_target'])\n",
    "    results.append({\"model\":\"xgboost\",\"roc_auc\":roc,\"pr_auc\":pr,\"best_f1\":best_f1,\"precision_at_best_f1\":p_f1,\"recall_at_best_f1\":r_f1,\"precision_at_recall_target\":p80,\"recall_at_recall_target\":r80})\n",
    "    thresholds['xgboost'] = {\"best_f1_threshold\":thr_f1, \"recall_target_threshold\":thr_rec}\n",
    "    model_objects['xgboost'] = xgb\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è XGBoost unavailable:\", repr(e))\n",
    "\n",
    "# --- Logistic Regression (baseline linear) ---\n",
    "try:\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    num_cols = [c for c in X_train.columns if pd.api.types.is_numeric_dtype(X_train[c])]\n",
    "    cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ], remainder=\"passthrough\")\n",
    "    logreg = Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"clf\", LogisticRegression(**CONFIG['models']['logreg']))\n",
    "    ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "    valid_proba = logreg.predict_proba(X_valid)[:,1]\n",
    "    roc = roc_auc_score(y_valid, valid_proba)\n",
    "    pr = average_precision_score(y_valid, valid_proba)\n",
    "    thr_f1, best_f1, p_f1, r_f1 = best_f1_threshold(y_valid, valid_proba)\n",
    "    thr_rec, p80, r80 = recall_target_threshold(y_valid, valid_proba, CONFIG['split']['recall_target'])\n",
    "    results.append({\"model\":\"logreg\",\"roc_auc\":roc,\"pr_auc\":pr,\"best_f1\":best_f1,\"precision_at_best_f1\":p_f1,\"recall_at_best_f1\":r_f1,\"precision_at_recall_target\":p80,\"recall_at_recall_target\":r80})\n",
    "    thresholds['logreg'] = {\"best_f1_threshold\":thr_f1, \"recall_target_threshold\":thr_rec}\n",
    "    model_objects['logreg'] = logreg\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Logistic Regression unavailable:\", repr(e))\n",
    "\n",
    "pd.DataFrame(results).sort_values([\"recall_at_recall_target\",\"pr_auc\",\"roc_auc\"], ascending=[False, False, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31b9af",
   "metadata": {},
   "source": [
    "## üèÖ Select Best Model (Recall-first) & Export Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(CONFIG['output']['model_dir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "if len(res_df)==0:\n",
    "    raise RuntimeError(\"No models trained successfully. Check dependencies.\")\n",
    "\n",
    "# Sort by recall@target desc, then PR-AUC, then ROC-AUC\n",
    "res_df_sorted = res_df.sort_values([\"recall_at_recall_target\",\"pr_auc\",\"roc_auc\"], ascending=[False, False, False]).reset_index(drop=True)\n",
    "best_row = res_df_sorted.iloc[0]\n",
    "best_model_name = best_row[\"model\"]\n",
    "best_model = model_objects[best_model_name]\n",
    "best_thresholds = thresholds[best_model_name]\n",
    "\n",
    "print(\"Best model (Recall-first):\", best_model_name)\n",
    "display(res_df_sorted)\n",
    "\n",
    "# Save metrics & thresholds\n",
    "with open(CONFIG['output']['metrics_path'], 'w') as f:\n",
    "    json.dump(res_df_sorted.to_dict(orient='records'), f, indent=2)\n",
    "with open(CONFIG['output']['thresholds_path'], 'w') as f:\n",
    "    json.dump(thresholds, f, indent=2)\n",
    "\n",
    "# Persist model (CatBoost has native save; others via joblib)\n",
    "model_path = None\n",
    "try:\n",
    "    if best_model_name == 'catboost':\n",
    "        model_path = str(Path(CONFIG['output']['model_dir']) / 'catboost_best.cbm')\n",
    "        best_model.save_model(model_path)\n",
    "    else:\n",
    "        import joblib\n",
    "        model_path = str(Path(CONFIG['output']['model_dir']) / f\"{best_model_name}_best.joblib\")\n",
    "        joblib.dump(best_model, model_path)\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Failed to persist model:\", repr(e))\n",
    "\n",
    "{\n",
    "    \"best_model\": best_model_name,\n",
    "    \"model_path\": model_path,\n",
    "    \"metrics_json\": CONFIG['output']['metrics_path'],\n",
    "    \"thresholds_json\": CONFIG['output']['thresholds_path']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809f7e9",
   "metadata": {},
   "source": [
    "## üìà (Optional) MLflow Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG['mlflow']['enabled']:\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(CONFIG['mlflow']['tracking_uri'] or 'file://' + str(Path(ARTIFACT_DIR).absolute()))\n",
    "    mlflow.set_experiment(CONFIG['mlflow']['experiment_name'])\n",
    "    with mlflow.start_run(run_name=f\"model-selection-{RUN_TS}\") as run:\n",
    "        mlflow.log_params({\n",
    "            \"seed\": SEED,\n",
    "            \"source\": CONFIG['data']['source'],\n",
    "            \"time_col\": CONFIG['columns']['time_col'],\n",
    "            \"recall_target\": CONFIG['split']['recall_target']\n",
    "        })\n",
    "        mlflow.log_artifact(CONFIG['output']['metrics_path'])\n",
    "        mlflow.log_artifact(CONFIG['output']['thresholds_path'])\n",
    "        if 'model_path' in locals() and model_path:\n",
    "            mlflow.log_artifact(model_path)\n",
    "        print(\"MLflow run:\", run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b336d9c",
   "metadata": {},
   "source": [
    "## üî¨ Sanity Check: Train vs Valid (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "best = best_model\n",
    "if best_model_name=='catboost':\n",
    "    val_scores = best.predict_proba(valid_pool)[:,1]\n",
    "else:\n",
    "    val_scores = best.predict_proba(X_valid)[:,1]\n",
    "\n",
    "thr = best_thresholds['recall_target_threshold']\n",
    "y_pred_val = (val_scores >= thr).astype(int)\n",
    "print(\"Validation recall at target threshold:\", recall_score(y_valid, y_pred_val))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_valid, y_pred_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
