{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f736fde",
   "metadata": {},
   "source": [
    "# ğŸ“Š Week 1 â€” Exploratory Data Analysis (EDA): Reading Guide\n",
    "\n",
    "**Learning Objectives (Week 1 â€“ EDA)**  \n",
    "- Understand the motivation for MLOps and how EDA fits into a production ML lifecycle.  \n",
    "- Connect to Redshift (or load a local fallback dataset) and perform reproducible EDA.  \n",
    "- Document data quality issues and define target/feature schema.  \n",
    "- Prepare train/validation/test splits with leakage-aware methodology.  \n",
    "\n",
    "> **Context**: ZAP is targeting **MLOps Level 2**. Even EDA should be reproducible and versioned (data query, sampling, and preprocessing code committed; tracked with MLflow where possible).\n",
    "\n",
    "## ğŸ” What is EDA and Why It Matters\n",
    "Exploratory Data Analysis (EDA) is the process of **exploring, visualizing, and validating datasets** before training models.  \n",
    "In **MLOps**, EDA is about much more than plots â€” itâ€™s about **data reliability** and ensuring downstream pipelines are stable.\n",
    "\n",
    "**Why it matters for production:**\n",
    "- ğŸ—‘ï¸ **Garbage in, garbage out** â†’ poor data = poor models.  \n",
    "- âš¡ **Operational resilience** â†’ detect defects early, before they hit production.  \n",
    "- ğŸ” **Pipeline reliability** â†’ schemas and checks from EDA become the foundation for automation.  \n",
    "\n",
    "\n",
    "## ğŸ“ Data Quality Dimensions\n",
    "Checking data quality ensures your model wonâ€™t collapse when facing real-world inputs. Here are the key dimensions:\n",
    "\n",
    "| Dimension    | Question to Ask | Example Issue |\n",
    "|--------------|-----------------|---------------|\n",
    "| âœ… Completeness | Are required values present? | Missing customer age |\n",
    "| ğŸ”„ Consistency | Do values follow expected formats/relations? | Country code \"PT\" inconsistently mapped |\n",
    "| ğŸ¯ Accuracy | Are values correct? | Negative product price |\n",
    "| ğŸ§© Validity | Do values conform to rules/types? | Dates stored as free-text |\n",
    "| â±ï¸ Timeliness | Is the data up to date? | Using last yearâ€™s sales for todayâ€™s forecast |\n",
    "\n",
    "\n",
    "## âš ï¸ Leakage and Target Contamination\n",
    "- **Data leakage** â†’ using information not available at prediction time.  \n",
    "- **Target contamination** â†’ when the target leaks into features or data splits.  \n",
    "\n",
    "âŒ Example leakage: Using \"credit approval status\" as a feature to predict loan approval.  \n",
    "âŒ Example contamination: Randomly splitting time-series data, letting future events â€œleakâ€ into training.\n",
    "\n",
    "â¡ï¸ Both lead to inflated metrics **during training** and catastrophic failures **in production**.\n",
    "\n",
    "\n",
    "## â™»ï¸ Reproducibility\n",
    "Reproducibility = **same results given same inputs**. Essential for trust, debugging, and collaboration.\n",
    "\n",
    "Key practices:\n",
    "- ğŸ² **Fixed seeds** â†’ ensure reproducible sampling/splitting.  \n",
    "- ğŸ“‘ **Deterministic queries** â†’ e.g., always `ORDER BY id` in SQL.  \n",
    "- ğŸ–¥ï¸ **Environment capture** â†’ record Python & library versions, OS, hardware.  \n",
    "\n",
    "Without reproducibility â†’ experiments canâ€™t be compared, bugs canâ€™t be traced.\n",
    "\n",
    "\n",
    "## ğŸ“¦ Outputs That Feed the Pipeline\n",
    "EDA is not a one-off. Its **outputs become artifacts** for the ML pipeline:\n",
    "\n",
    "- ğŸ—‚ï¸ **Feature schema** â†’ defines types, ranges, categories, nullability.  \n",
    "- âœ… **Data checks** â†’ rules like â€œno nulls in IDsâ€ or â€œtarget is binary.â€  \n",
    "- âœ‚ï¸ **Split strategy** â†’ deterministic, leakage-free train/val/test partitions.  \n",
    "\n",
    "These artifacts support:\n",
    "- Automation in CI/CD âœ…  \n",
    "- Monitoring in production ğŸ“ˆ  \n",
    "- MLOps Level 2 maturity âš™ï¸  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daed676",
   "metadata": {},
   "source": [
    "# ğŸ“ Exercises - Telco Customer Churn Dataset\n",
    "\n",
    "We will use the **Telco Customer Churn dataset** from Kaggle to practice EDA.  \n",
    "This dataset contains customer demographics, services, account info, and a churn label.\n",
    "\n",
    "\n",
    "## ğŸ”§ Setup\n",
    "Use the provided code snippet to download the dataset:\n",
    "\n",
    "```python\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Load the latest version of the dataset\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"blastchar/telco-customer-churn\",\n",
    "  file_path=\"\",  # leave empty to load the main CSV\n",
    ")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73d89c",
   "metadata": {},
   "source": [
    "## 1. Data Overview & Metadata\n",
    "Inspect the dataset:\n",
    "- Number of rows and columns.  \n",
    "- Data types of each column.  \n",
    "- Identify categorical, numerical, and target (`Churn`) variables.  \n",
    "- Create a **data dictionary** in Markdown: column name â†’ description â†’ expected type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1f4ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753d30f",
   "metadata": {},
   "source": [
    "## 2. Data Quality Checks\n",
    "Check the **5 quality dimensions** on this dataset:\n",
    "\n",
    "| Dimension    | Task |\n",
    "|--------------|------|\n",
    "| âœ… Completeness | Count missing/null values in each column. |\n",
    "| ğŸ”„ Consistency | Look for inconsistent categories (e.g., â€œMaleâ€ vs. â€œmaleâ€). |\n",
    "| ğŸ¯ Accuracy | Spot anomalies (e.g., negative charges). |\n",
    "| ğŸ§© Validity | Ensure `TotalCharges â‰ˆ MonthlyCharges Ã— tenure`. |\n",
    "| â±ï¸ Timeliness | Discuss whether tenure captures freshness of data. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5328173",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2e947",
   "metadata": {},
   "source": [
    "## 3. Target Variable Exploration\n",
    "- Plot the distribution of `Churn` (Yes/No).  \n",
    "- Compute churn rate (%).  \n",
    "- Discuss if the dataset is **imbalanced** and what that implies for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0150d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7014bbc8",
   "metadata": {},
   "source": [
    "## 4. Univariate Analysis\n",
    "- For numerical columns (e.g., `tenure`, `MonthlyCharges`, `TotalCharges`):  \n",
    "  - Plot histograms & boxplots.  \n",
    "  - Identify outliers and skewed distributions.  \n",
    "\n",
    "- For categorical columns (e.g., `Contract`, `InternetService`, `PaymentMethod`):  \n",
    "  - Plot bar charts of category counts.  \n",
    "  - Check if categories have enough representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a832e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0066966",
   "metadata": {},
   "source": [
    "## 5. Bivariate Analysis (Churn vs. Features)\n",
    "- Compare churn rates across categories:  \n",
    "  - Gender vs. Churn  \n",
    "  - Contract type vs. Churn  \n",
    "  - InternetService vs. Churn  \n",
    "\n",
    "- Compare churn rates across numerical features:  \n",
    "  - Plot churn vs. tenure (does retention improve with longer tenure?).  \n",
    "  - Compare average `MonthlyCharges` for churned vs. non-churned customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497f01b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f1a90d",
   "metadata": {},
   "source": [
    "## 7. Reproducibility Practices\n",
    "- Set a **random seed** when sampling rows for inspection.  \n",
    "- Save an **EDA profile report** (e.g., using `pandas-profiling` or `ydata-profiling`).  \n",
    "- Export a **feature schema JSON** with column names, types, and allowed ranges/categories.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997c649",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b45b91",
   "metadata": {},
   "source": [
    "## 8. Train/Validation/Test Split Strategy\n",
    "- Propose and implement a split strategy:  \n",
    "  - Random stratified split by `Churn`.  \n",
    "  - Ensure reproducibility with a fixed random seed.  \n",
    "  - Document why stratification is necessary here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e4d96",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b664b6",
   "metadata": {},
   "source": [
    "# ğŸ¯ Deliverables\n",
    "By the end of these exercises, you should have:\n",
    "1. A **data dictionary**.  \n",
    "2. Summary tables/plots of churn and key features.  \n",
    "3. A **feature schema JSON** with data types and constraints.  \n",
    "4. A **train/val/test split file** (e.g., `splits.json`) for reproducible downstream tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929c796",
   "metadata": {},
   "source": [
    "## Peer Validation\n",
    "  - Reproducible data loading (query or seed).  \n",
    "  - Clear schema with rationale per feature.  \n",
    "  - Split method documented and leakage-safe.  \n",
    "  - Artifacts present and versioned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
