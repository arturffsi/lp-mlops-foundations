{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f36c816",
   "metadata": {},
   "source": [
    "# 🚀 Deployment — **Example Notebook** (SageMaker-ready)\n",
    "\n",
    "This notebook **continues after** `evaluation_example.ipynb` and `validation_example.ipynb` to **deploy** a validated candidate to production using **Amazon SageMaker**.\n",
    "\n",
    "### 🎯 Goals of this step\n",
    "- **Serve predictions reliably**: create a secure, scalable, observable inference endpoint (real-time or serverless).\n",
    "- **Safe rollout**: canary / blue‑green traffic shifting with **automatic rollback** helper.\n",
    "- **Production guardrails**: data capture, CloudWatch logs, autoscaling, alarms, and **Model Monitor** schedules.\n",
    "- **Governance**: source the **Approved** model from the **Model Registry** and tag artifacts for lineage.\n",
    "- **Idempotency**: re‑runs won’t create duplicate resources; updates are safe.\n",
    "\n",
    "> Places you must customize are marked with **`# <- TODO ✏️`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80e351",
   "metadata": {},
   "source": [
    "## 🧰 Prerequisites\n",
    "Uncomment if your kernel is missing packages (Studio often has most already):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c535860",
   "metadata": {},
   "source": [
    "\n",
    "## 🏆 Champion Auto‑Selection & Lineage\n",
    "\n",
    "This notebook will **automatically locate the champion** model in the **SageMaker Model Registry** based on a tag such as **`candidate_run_id`** emitted by `validation_example.ipynb`.  \n",
    "It will then propagate **lineage tags** (e.g., `candidate_run_id`, `data_version`, `eval_mean_recall@target`) to:\n",
    "- Model (CreateModel or ModelPackage container)\n",
    "- EndpointConfig\n",
    "- Endpoint\n",
    "\n",
    "> Customize the keys you emit from validation and the keys you want to tag onto the deployed resources. Look for **`# <- TODO ✏️`** markers below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e722a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install boto3 sagemaker pandas numpy s3fs pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5fd62",
   "metadata": {},
   "source": [
    "## 🚪 SageMaker Studio Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, boto3, json, time, datetime\n",
    "from pathlib import Path\n",
    "try:\n",
    "    import sagemaker\n",
    "    sm_sess = sagemaker.Session()\n",
    "    region = boto3.Session().region_name or os.getenv(\"AWS_REGION\",\"\")\n",
    "    try:\n",
    "        role = sagemaker.get_execution_role()\n",
    "    except Exception:\n",
    "        role = os.getenv(\"SAGEMAKER_ROLE\",\"\")\n",
    "    bucket = sm_sess.default_bucket()\n",
    "    print(\"✅ SageMaker context\")\n",
    "    print(\" Region:\", region)\n",
    "    print(\" Role:  \", role)\n",
    "    print(\" Bucket:\", bucket)\n",
    "    os.environ.setdefault(\"AWS_REGION\", region or \"\")\n",
    "    os.environ.setdefault(\"SM_DEFAULT_BUCKET\", bucket or \"\")\n",
    "except Exception as e:\n",
    "    print(\"ℹ️ Running without SageMaker context. Reason:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5ea9a",
   "metadata": {},
   "source": [
    "## ⚙️ Configuration — **edit here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be14444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TS = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "CONFIG = {\n",
    "    \"lineage\": {\n",
    "        \"candidate_run_id\": os.getenv(\"CANDIDATE_RUN_ID\",\"\"),  # <- TODO ✏️ If set, we will look for a model package tagged with this run id\n",
    "        \"require_champion_tag\": True,                           # <- TODO ✏️ If True, prefer packages tagged is_champion=true\n",
    "        # Map tags -> keys you expect from validation time (either Tags or CustomerMetadataProperties on ModelPackage)\n",
    "        \"expected_keys\": [                                      # <- TODO ✏️ customize your lineage keys\n",
    "            \"candidate_run_id\", \"data_version\", \"feature_schema_path\",\n",
    "            \"splits_path\", \"eval_mean_recall_at_target\", \"eval_roc_auc\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"source\": {\n",
    "        \"type\": os.getenv(\"MODEL_SOURCE\",\"registry\"),                       # 'registry' | 'artifact'  # <- TODO ✏️\n",
    "        \"package_group\": os.getenv(\"MODEL_PACKAGE_GROUP\",\"churn-model-group\"), # <- TODO ✏️ (if using registry)\n",
    "        \"approval_status\": os.getenv(\"MODEL_APPROVAL_STATUS\",\"Approved\"),      # Approved | PendingManualApproval\n",
    "        \"specific_package_arn\": os.getenv(\"MODEL_PACKAGE_ARN\",\"\"),             # optional precise ARN\n",
    "        # For 'artifact' source (BYOC or framework container):\n",
    "        \"model_tar\": os.getenv(\"MODEL_TAR\",\"model.tar.gz\"),                 # <- TODO ✏️ ensure file exists\n",
    "        \"inference_image_uri\": os.getenv(\"INFERENCE_IMAGE\",\"\"),             # <- TODO ✏️ e.g. prebuilt xgboost image\n",
    "        \"env\": {                                                           # optional container env\n",
    "            \"SAGEMAKER_PROGRAM\": os.getenv(\"SAGEMAKER_PROGRAM\",\"inference.py\"), # <- TODO ✏️ entrypoint inside tar\n",
    "            \"SAGEMAKER_SUBMIT_DIRECTORY\": os.getenv(\"SAGEMAKER_SUBMIT_DIRECTORY\",\"model.tar.gz\"),\n",
    "            \"SAGEMAKER_REQUIREMENTS\": os.getenv(\"SAGEMAKER_REQUIREMENTS\",\"requirements.txt\"),\n",
    "        },\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"endpoint_name\": os.getenv(\"ENDPOINT_NAME\", f\"churn-endpoint-{TS}\"), # <- TODO ✏️\n",
    "        \"instance_type\": os.getenv(\"INSTANCE_TYPE\",\"ml.m5.large\"),            # <- TODO ✏️\n",
    "        \"initial_instance_count\": int(os.getenv(\"INITIAL_INSTANCE_COUNT\",\"2\")),\n",
    "        \"serverless\": {                                                       # serverless optional\n",
    "            \"enabled\": os.getenv(\"SERVERLESS\",\"false\").lower()==\"true\",       # <- TODO ✏️ true to use serverless\n",
    "            \"memory_size_in_mb\": int(os.getenv(\"SVL_MEMORY\",\"4096\")),\n",
    "            \"max_concurrency\": int(os.getenv(\"SVL_MAX_CONCURRENCY\",\"10\")),\n",
    "        },\n",
    "        \"vpc\": {                                                              # optional VPC config\n",
    "            \"enable\": os.getenv(\"VPC_ENABLE\",\"false\").lower()==\"true\",        # <- TODO ✏️\n",
    "            \"subnets\": os.getenv(\"VPC_SUBNETS\",\"\").split(\",\") if os.getenv(\"VPC_SUBNETS\") else [],\n",
    "            \"security_group_ids\": os.getenv(\"VPC_SGS\",\"\").split(\",\") if os.getenv(\"VPC_SGS\") else [],\n",
    "        },\n",
    "        \"tags\": [ {\"Key\":\"project\",\"Value\":\"lp-mlops\"}, {\"Key\":\"stage\",\"Value\":\"prod\"} ],  # <- TODO ✏️\n",
    "        \"data_capture\": {\n",
    "            \"enable\": os.getenv(\"DATA_CAPTURE\",\"true\").lower()==\"true\",       # <- TODO ✏️\n",
    "            \"sampling_percentage\": int(os.getenv(\"CAPTURE_PCT\",\"50\")),\n",
    "            \"s3_prefix\": os.getenv(\"CAPTURE_PREFIX\", f\"s3://{os.getenv('SM_DEFAULT_BUCKET','')}/data-capture/{TS}\"),\n",
    "            \"capture_content_type_header\": {\"CsvContentTypes\": [\"text/csv\"], \"JsonContentTypes\": [\"application/json\"]},\n",
    "            \"enable_inference_input\": True,\n",
    "        },\n",
    "        \"rollout\": {\n",
    "            \"strategy\": os.getenv(\"ROLLOUT\",\"canary\"),                         # 'all-at-once' | 'canary' | 'blue-green'  # <- TODO ✏️\n",
    "            \"canary_percent\": int(os.getenv(\"CANARY_PERCENT\",\"10\")),           # percentage for new variant\n",
    "            \"bake_minutes\": int(os.getenv(\"BAKE_MIN\",\"15\")),                   # bake time before full shift\n",
    "        }\n",
    "    },\n",
    "    \"autoscaling\": {\n",
    "        \"enable\": os.getenv(\"AUTOSCALING\",\"true\").lower()==\"true\",            # <- TODO ✏️\n",
    "        \"min_capacity\": int(os.getenv(\"AS_MIN\",\"2\")),\n",
    "        \"max_capacity\": int(os.getenv(\"AS_MAX\",\"6\")),\n",
    "        \"target_invocations_per_min\": int(os.getenv(\"AS_TARGET\",\"600\")),      # ~10 RPS per instance\n",
    "        \"scale_in_cooldown\": int(os.getenv(\"AS_IN_COOLDOWN\",\"120\")),\n",
    "        \"scale_out_cooldown\": int(os.getenv(\"AS_OUT_COOLDOWN\",\"60\")),\n",
    "    },\n",
    "    \"monitoring\": {\n",
    "        \"enable\": os.getenv(\"MONITORING\",\"true\").lower()==\"true\",             # <- TODO ✏️\n",
    "        \"baseline_dataset_uri\": os.getenv(\"BASELINE_S3\",\"\"),                  # <- TODO ✏️ (optional) S3 with baseline data\n",
    "        \"schedule_cron\": os.getenv(\"MON_CRON\",\"cron(0 * * * ? *)\"),           # hourly\n",
    "        \"instance_type\": os.getenv(\"MON_INSTANCE\",\"ml.m5.large\"),\n",
    "        \"volume_size_gb\": int(os.getenv(\"MON_VOL\",\"30\")),\n",
    "        \"max_runtime_seconds\": int(os.getenv(\"MON_MAXRUN\",\"3600\")),\n",
    "    }\n",
    "}\n",
    "\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de53c37",
   "metadata": {},
   "source": [
    "## 🧱 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "rt = boto3.client(\"sagemaker-runtime\")\n",
    "appscaling = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "def ensure_model_from_registry(cfg):\n",
    "    # choose latest Approved (unless specific ARN provided)\n",
    "    if cfg[\"source\"][\"specific_package_arn\"]:\n",
    "        arn = cfg[\"source\"][\"specific_package_arn\"]\n",
    "        print(\"Using specified package:\", arn)\n",
    "        return arn\n",
    "    res = sm.list_model_packages(ModelPackageGroupName=cfg[\"source\"][\"package_group\"], SortBy=\"CreationTime\", SortOrder=\"Descending\", MaxResults=50)\n",
    "    for it in res.get(\"ModelPackageSummaryList\", []):\n",
    "        if it.get(\"ModelApprovalStatus\") == cfg[\"source\"][\"approval_status\"]:\n",
    "            print(\"Selected Approved package:\", it[\"ModelPackageArn\"])\n",
    "            return it[\"ModelPackageArn\"]\n",
    "    raise RuntimeError(\"No Approved package found. Adjust approval status or package group.\")\n",
    "\n",
    "def ensure_model_from_artifact(cfg, model_name):\n",
    "    image = cfg[\"source\"][\"inference_image_uri\"]\n",
    "    assert image, \"inference_image_uri is required for 'artifact' source\"\n",
    "    model_data = cfg[\"source\"][\"model_tar\"]\n",
    "    assert Path(model_data).exists(), f\"Missing model tar: {model_data}\"\n",
    "    vpc_config = None\n",
    "    if cfg[\"deployment\"][\"vpc\"][\"enable\"]:\n",
    "        vpc_config = {\n",
    "            \"Subnets\": cfg[\"deployment\"][\"vpc\"][\"subnets\"],\n",
    "            \"SecurityGroupIds\": cfg[\"deployment\"][\"vpc\"][\"security_group_ids\"]\n",
    "        }\n",
    "    try:\n",
    "        sm.describe_model(ModelName=model_name)\n",
    "        print(\"Model already exists:\", model_name)\n",
    "    except sm.exceptions.ClientError:\n",
    "        sm.create_model(\n",
    "            ModelName=model_name,\n",
    "            PrimaryContainer={\n",
    "                \"Image\": image,\n",
    "                \"ModelDataUrl\": model_data if model_data.startswith(\"s3://\") else None,\n",
    "                \"Mode\": \"SingleModel\",\n",
    "                \"Environment\": cfg[\"source\"][\"env\"],\n",
    "            },\n",
    "            ExecutionRoleArn=os.getenv(\"SAGEMAKER_ROLE\") or os.getenv(\"ROLE_ARN\") or \"\",\n",
    "            VpcConfig=vpc_config or {},\n",
    "            Tags=CONFIG['deployment']['tags']\n",
    "        )\n",
    "        print(\"Created Model:\", model_name)\n",
    "    return model_name\n",
    "\n",
    "def current_endpoint_config_name(endpoint_name):\n",
    "    try:\n",
    "        desc = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "        return desc.get(\"EndpointConfigName\"), desc.get(\"EndpointStatus\")\n",
    "    except sm.exceptions.ClientError:\n",
    "        return None, None\n",
    "\n",
    "def wait_endpoint(endpoint_name):\n",
    "    print(\"⏳ Waiting for endpoint:\", endpoint_name)\n",
    "    wait = True\n",
    "    while wait:\n",
    "        desc = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "        st = desc[\"EndpointStatus\"]\n",
    "        print(\"  status:\", st)\n",
    "        if st in [\"InService\", \"Failed\"]:\n",
    "            break\n",
    "        time.sleep(30)\n",
    "    if st == \"Failed\":\n",
    "        print(\"❌ Endpoint failed:\", desc.get(\"FailureReason\"))\n",
    "        raise RuntimeError(desc.get(\"FailureReason\"))\n",
    "    print(\"✅ Endpoint InService.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3cdbc",
   "metadata": {},
   "source": [
    "\n",
    "### 🔎 Champion resolver (Registry)\n",
    "Searches for a **Model Package** in the specified **Model Package Group** with:\n",
    "1) matching `candidate_run_id` (if provided), else\n",
    "2) a tag `is_champion=true` (if `require_champion_tag=True`), else\n",
    "3) the **latest Approved** package.\n",
    "It also collects lineage keys from **Tags** and **CustomerMetadataProperties**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def _tags_to_dict(tags: List[dict]) -> Dict[str, str]:\n",
    "    out = {}\n",
    "    for t in tags or []:\n",
    "        k, v = t.get(\"Key\"), t.get(\"Value\")\n",
    "        if k is not None and v is not None:\n",
    "            out[str(k)] = str(v)\n",
    "    return out\n",
    "\n",
    "def collect_lineage_from_package(model_package_arn: str, expected_keys: List[str]) -> Dict[str, str]:\n",
    "    d = sm.describe_model_package(ModelPackageName=model_package_arn)\n",
    "    tag_map = _tags_to_dict(sm.list_tags(ResourceArn=model_package_arn).get(\"Tags\", []))\n",
    "    # Pull supplemental keys from CustomerMetadataProperties if present\n",
    "    cmp = d.get(\"CustomerMetadataProperties\") or {}\n",
    "    lineage = {}\n",
    "    for k in expected_keys:\n",
    "        if k in tag_map:\n",
    "            lineage[k] = tag_map[k]\n",
    "        elif k in cmp:\n",
    "            lineage[k] = cmp[k]\n",
    "    # Also try to surface a couple of quality metrics if present in ModelMetrics\n",
    "    mm = d.get(\"ModelMetrics\") or {}\n",
    "    if \"ModelQuality\" in mm and \"Statistics\" in mm[\"ModelQuality\"] and \"S3Uri\" in mm[\"ModelQuality\"][\"Statistics\"]:\n",
    "        lineage.setdefault(\"model_quality_stats_s3\", mm[\"ModelQuality\"][\"Statistics\"][\"S3Uri\"])\n",
    "    return lineage\n",
    "\n",
    "def resolve_champion_package(cfg: dict) -> Dict[str, str]:\n",
    "    group = cfg[\"source\"][\"package_group\"]\n",
    "    approval = cfg[\"source\"][\"approval_status\"]\n",
    "    candidate_run_id = cfg[\"lineage\"][\"candidate_run_id\"]\n",
    "    need_champion = cfg[\"lineage\"][\"require_champion_tag\"]\n",
    "    expected_keys = cfg[\"lineage\"][\"expected_keys\"]\n",
    "    # Scan registry\n",
    "    paginator = sm.get_paginator(\"list_model_packages\")\n",
    "    for page in paginator.paginate(ModelPackageGroupName=group, SortBy=\"CreationTime\", SortOrder=\"Descending\"):\n",
    "        for summary in page.get(\"ModelPackageSummaryList\", []):\n",
    "            if summary.get(\"ModelApprovalStatus\") != approval:\n",
    "                continue\n",
    "            arn = summary[\"ModelPackageArn\"]\n",
    "            tags = _tags_to_dict(sm.list_tags(ResourceArn=arn).get(\"Tags\", []))\n",
    "            # 1) candidate_run_id exact match\n",
    "            if candidate_run_id and tags.get(\"candidate_run_id\") == candidate_run_id:\n",
    "                print(\"✅ Found package with candidate_run_id:\", candidate_run_id)\n",
    "                return {\"arn\": arn, \"lineage\": collect_lineage_from_package(arn, expected_keys)}\n",
    "            # 2) champion tag\n",
    "            if need_champion and tags.get(\"is_champion\",\"\").lower() == \"true\":\n",
    "                print(\"✅ Found package tagged as champion\")\n",
    "                return {\"arn\": arn, \"lineage\": collect_lineage_from_package(arn, expected_keys)}\n",
    "            # else fallback continues\n",
    "    # 3) Fallback: latest Approved\n",
    "    first_page = sm.list_model_packages(ModelPackageGroupName=group, SortBy=\"CreationTime\", SortOrder=\"Descending\", MaxResults=10)\n",
    "    for s in first_page.get(\"ModelPackageSummaryList\", []):\n",
    "        if s.get(\"ModelApprovalStatus\") == approval:\n",
    "            arn = s[\"ModelPackageArn\"]\n",
    "            print(\"ℹ️ Falling back to latest Approved package.\")\n",
    "            return {\"arn\": arn, \"lineage\": collect_lineage_from_package(arn, expected_keys)}\n",
    "    raise RuntimeError(\"No Approved model package found to deploy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87c48a",
   "metadata": {},
   "source": [
    "## 🧭 Plan the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cceb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_type = CONFIG[\"source\"][\"type\"]\n",
    "endpoint_name = CONFIG[\"deployment\"][\"endpoint_name\"]\n",
    "model_name_new = f\"{endpoint_name}-model-{TS}\"\n",
    "endpoint_config_name_new = f\"{endpoint_name}-cfg-{TS}\"\n",
    "\n",
    "common_tags = CONFIG[\"deployment\"][\"tags\"].copy()\n",
    "\n",
    "if source_type == \"registry\":\n",
    "    resolved = resolve_champion_package(CONFIG)\n",
    "    package_arn = resolved[\"arn\"]\n",
    "    lineage_tags = [{\"Key\": k, \"Value\": str(v)} for k, v in resolved[\"lineage\"].items()]\n",
    "    # Keep these visible across resources\n",
    "    common_tags += lineage_tags + [\n",
    "        {\"Key\":\"deployed_from\",\"Value\":\"model-registry\"},\n",
    "        {\"Key\":\"model_package_arn\",\"Value\":package_arn},\n",
    "    ]\n",
    "    model_package_container = {\"ModelPackageArn\": package_arn}\n",
    "    print(\"Will deploy from Model Package (champion):\", package_arn)\n",
    "else:\n",
    "    # Artifact route: you can also load lineage from a local JSON if produced in validation\n",
    "    # e.g., with keys in CONFIG['lineage']['expected_keys']  # <- TODO ✏️\n",
    "    lineage_tags = []\n",
    "    model_name = ensure_model_from_artifact(CONFIG, model_name_new)\n",
    "    common_tags += lineage_tags + [\n",
    "        {\"Key\":\"deployed_from\",\"Value\":\"artifact\"},\n",
    "        {\"Key\":\"model_artifact\",\"Value\":CONFIG[\"source\"][\"model_tar\"]},\n",
    "    ]\n",
    "    print(\"Will deploy from local artifact as model:\", model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bbe3d",
   "metadata": {},
   "source": [
    "## 🧩 Create EndpointConfig (single / canary / blue‑green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capture_cfg = None\n",
    "if CONFIG[\"deployment\"][\"data_capture\"][\"enable\"]:\n",
    "    data_capture_cfg = {\n",
    "        \"EnableCapture\": True,\n",
    "        \"InitialSamplingPercentage\": CONFIG[\"deployment\"][\"data_capture\"][\"sampling_percentage\"],\n",
    "        \"DestinationS3Uri\": CONFIG[\"deployment\"][\"data_capture\"][\"s3_prefix\"],\n",
    "        \"CaptureOptions\": [{\"CaptureMode\": \"Input\"}, {\"CaptureMode\": \"Output\"}],\n",
    "        \"CaptureContentTypeHeader\": CONFIG[\"deployment\"][\"data_capture\"][\"capture_content_type_header\"]\n",
    "    }\n",
    "\n",
    "variant_new = {\n",
    "    \"VariantName\": \"variant-new\",\n",
    "    \"InitialVariantWeight\": 1.0,\n",
    "    \"InitialInstanceCount\": CONFIG[\"deployment\"][\"initial_instance_count\"],\n",
    "    \"InstanceType\": CONFIG[\"deployment\"][\"instance_type\"],\n",
    "}\n",
    "\n",
    "serverless = CONFIG[\"deployment\"][\"serverless\"]\n",
    "if serverless[\"enabled\"]:\n",
    "    variant_new[\"ServerlessConfig\"] = {\n",
    "        \"MemorySizeInMB\": serverless[\"memory_size_in_mb\"],\n",
    "        \"MaxConcurrency\": serverless[\"max_concurrency\"]\n",
    "    }\n",
    "    variant_new.pop(\"InitialInstanceCount\", None)\n",
    "    variant_new.pop(\"InstanceType\", None)\n",
    "\n",
    "# Build container spec\n",
    "if CONFIG[\"source\"][\"type\"] == \"registry\":\n",
    "    containers = [model_package_container]\n",
    "else:\n",
    "    containers = [{\n",
    "        \"Image\": CONFIG[\"source\"][\"inference_image_uri\"],\n",
    "        \"ModelDataUrl\": CONFIG[\"source\"][\"model_tar\"] if str(CONFIG[\"source\"][\"model_tar\"]).startswith(\"s3://\") else \"\",\n",
    "        \"Environment\": CONFIG[\"source\"][\"env\"]\n",
    "    }]\n",
    "\n",
    "# Determine rollout strategy\n",
    "strategy = CONFIG[\"deployment\"][\"rollout\"][\"strategy\"]\n",
    "prev_cfg_name, ep_status = current_endpoint_config_name(endpoint_name)\n",
    "\n",
    "if strategy == \"all-at-once\" or prev_cfg_name is None:\n",
    "    # Single variant\n",
    "    production_variants = [variant_new]\n",
    "else:\n",
    "    # Canary / blue‑green: include previous variant with higher weight\n",
    "    canary_pct = CONFIG[\"deployment\"][\"rollout\"][\"canary_percent\"] / 100.0\n",
    "    variant_old = {\n",
    "        \"VariantName\": \"variant-old\",\n",
    "        \"InitialVariantWeight\": max(0.0, 1.0 - canary_pct),\n",
    "    }\n",
    "    # you must copy instance/serverless settings of the existing endpoint; for brevity use same as new\n",
    "    if not serverless[\"enabled\"]:\n",
    "        variant_old.update({\n",
    "            \"InitialInstanceCount\": CONFIG[\"deployment\"][\"initial_instance_count\"],\n",
    "            \"InstanceType\": CONFIG[\"deployment\"][\"instance_type\"],\n",
    "        })\n",
    "    else:\n",
    "        variant_old[\"ServerlessConfig\"] = variant_new[\"ServerlessConfig\"]\n",
    "\n",
    "    production_variants = [variant_old, variant_new]\n",
    "\n",
    "# Create EndpointConfig\n",
    "try:\n",
    "    sm.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name_new,\n",
    "        ProductionVariants=production_variants,\n",
    "        DataCaptureConfig=data_capture_cfg,\n",
    "        Tags=common_tags\n",
    "    )\n",
    "    print(\"Created EndpointConfig:\", endpoint_config_name_new)\n",
    "except sm.exceptions.ClientError as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(\"EndpointConfig exists:\", endpoint_config_name_new)\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd7a29",
   "metadata": {},
   "source": [
    "## 🚀 Create / Update Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd38fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create endpoint if it does not exist, else update\n",
    "try:\n",
    "    sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(\"Updating endpoint:\", endpoint_name)\n",
    "    sm.update_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name_new)\n",
    "except sm.exceptions.ClientError:\n",
    "    print(\"Creating endpoint:\", endpoint_name)\n",
    "    sm.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name_new, Tags=CONFIG[\"deployment\"][\"tags\"])\n",
    "\n",
    "wait_endpoint(endpoint_name)\n",
    "\n",
    "if strategy in [\"canary\",\"blue-green\"]:\n",
    "    print(\"🧪 Canary bake period (minutes):\", CONFIG[\"deployment\"][\"rollout\"][\"bake_minutes\"])\n",
    "    time.sleep(1)  # keep short for example; in real life, wait bake_minutes * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a198792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure endpoint carries lineage tags (update_endpoint doesn't accept Tags)\n",
    "try:\n",
    "    ep = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    ep_arn = ep[\"EndpointArn\"]\n",
    "    sm.add_tags(ResourceArn=ep_arn, Tags=common_tags)\n",
    "    print(\"✅ Applied lineage tags to Endpoint\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Could not tag endpoint:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6d5ed",
   "metadata": {},
   "source": [
    "## 📈 (Optional) Autoscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"autoscaling\"][\"enable\"] and not CONFIG[\"deployment\"][\"serverless\"][\"enabled\"]:\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/variant-new\"\n",
    "    ns = \"sagemaker\"\n",
    "    try:\n",
    "        appscaling.register_scalable_target(\n",
    "            ServiceNamespace=ns,\n",
    "            ResourceId=resource_id,\n",
    "            ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "            MinCapacity=CONFIG[\"autoscaling\"][\"min_capacity\"],\n",
    "            MaxCapacity=CONFIG[\"autoscaling\"][\"max_capacity\"]\n",
    "        )\n",
    "        appscaling.put_scaling_policy(\n",
    "            PolicyName=f\"invocations-per-target-{endpoint_name}\",\n",
    "            ServiceNamespace=ns,\n",
    "            ResourceId=resource_id,\n",
    "            ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "            PolicyType=\"TargetTrackingScaling\",\n",
    "            TargetTrackingScalingPolicyConfiguration={\n",
    "                \"TargetValue\": CONFIG[\"autoscaling\"][\"target_invocations_per_min\"],\n",
    "                \"PredefinedMetricSpecification\": {\"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"},\n",
    "                \"ScaleInCooldown\": CONFIG[\"autoscaling\"][\"scale_in_cooldown\"],\n",
    "                \"ScaleOutCooldown\": CONFIG[\"autoscaling\"][\"scale_out_cooldown\"]\n",
    "            }\n",
    "        )\n",
    "        print(\"✅ Autoscaling configured for\", resource_id)\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Autoscaling setup failed:\", e)\n",
    "else:\n",
    "    print(\"Autoscaling disabled or using Serverless (auto-managed).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829467a",
   "metadata": {},
   "source": [
    "## 🫖 Smoke Test — sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c122c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np, pandas as pd\n",
    "# Build a minimal JSON sample — replace with a real row from your schema\n",
    "# <- TODO ✏️ adjust payload format to your inference script or algorithm\n",
    "sample = [{\"age\": 45, \"tenure_months\": 12, \"monthly_charges\": 39.9, \"contract_type\": \"month-to-month\", \"country\": \"PT\"}]\n",
    "\n",
    "try:\n",
    "    resp = rt.invoke_endpoint(EndpointName=endpoint_name, ContentType=\"application/json\", Body=json.dumps(sample).encode(\"utf-8\"))\n",
    "    body = resp[\"Body\"].read().decode(\"utf-8\")\n",
    "    print(\"Response:\", body[:500])\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Inference failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822d410",
   "metadata": {},
   "source": [
    "## 🔀 Traffic Shift to 100% (after bake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"deployment\"][\"rollout\"][\"strategy\"] in [\"canary\",\"blue-green\"]:\n",
    "    # Update weights to 100% new variant\n",
    "    try:\n",
    "        # Rebuild EndpointConfig with 100% weight\n",
    "        endpoint_config_full = f\"{endpoint_name}-cfg-full-{TS}\"\n",
    "        variant_full = {\n",
    "            \"VariantName\": \"variant-new\",\n",
    "            \"InitialVariantWeight\": 1.0,\n",
    "            \"InitialInstanceCount\": CONFIG[\"deployment\"][\"initial_instance_count\"],\n",
    "            \"InstanceType\": CONFIG[\"deployment\"][\"instance_type\"],\n",
    "        }\n",
    "        if CONFIG[\"deployment\"][\"serverless\"][\"enabled\"]:\n",
    "            variant_full.pop(\"InitialInstanceCount\", None)\n",
    "            variant_full.pop(\"InstanceType\", None)\n",
    "            variant_full[\"ServerlessConfig\"] = {\n",
    "                \"MemorySizeInMB\": CONFIG[\"deployment\"][\"serverless\"][\"memory_size_in_mb\"],\n",
    "                \"MaxConcurrency\": CONFIG[\"deployment\"][\"serverless\"][\"max_concurrency\"]\n",
    "            }\n",
    "        sm.create_endpoint_config(EndpointConfigName=endpoint_config_full, ProductionVariants=[variant_full], DataCaptureConfig=data_capture_cfg)\n",
    "        sm.update_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_full)\n",
    "        wait_endpoint(endpoint_name)\n",
    "        print(\"✅ Shifted traffic to 100% new variant\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Traffic shift failed:\", e)\n",
    "else:\n",
    "    print(\"Not a canary/blue-green rollout; full traffic already on new variant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ec3e3",
   "metadata": {},
   "source": [
    "## ⏪ Rollback Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollback_to_previous_config(endpoint_name):\n",
    "    desc = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    hist = sm.list_endpoint_configs(SortBy=\"CreationTime\", SortOrder=\"Descending\", MaxResults=10)\n",
    "    current = desc[\"EndpointConfigName\"]\n",
    "    for ec in hist.get(\"EndpointConfigs\", []):\n",
    "        if ec[\"EndpointConfigName\"] != current:\n",
    "            sm.update_endpoint(EndpointName=endpoint_name, EndpointConfigName=ec[\"EndpointConfigName\"])\n",
    "            wait_endpoint(endpoint_name)\n",
    "            print(\"Rolled back to:\", ec[\"EndpointConfigName\"])\n",
    "            return ec[\"EndpointConfigName\"]\n",
    "    print(\"No previous config found.\")\n",
    "    return None\n",
    "\n",
    "# Example (disabled):\n",
    "# rollback_to_previous_config(CONFIG['deployment']['endpoint_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba381ee8",
   "metadata": {},
   "source": [
    "## 🧹 (Optional) Cleanup — **Danger zone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete endpoint after testing\n",
    "# sm.delete_endpoint(EndpointName=CONFIG[\"deployment\"][\"endpoint_name\"])\n",
    "# print(\"Deleted endpoint:\", CONFIG[\"deployment\"][\"endpoint_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34f0ea",
   "metadata": {},
   "source": [
    "## ✅ Best Practices Recap\n",
    "- **Governance**: pull the **Approved** candidate from **Model Registry**; keep lineage via tags & metadata.\n",
    "- **Security**: enable VPC, KMS encryption, proper IAM, and private subnets for endpoints.  # <- TODO ✏️\n",
    "- **Observability**: enable **data capture** and **CloudWatch** logs; define **alarms** for latency & errors.  # <- TODO ✏️\n",
    "- **Scalability**: use **Autoscaling** for instance endpoints or **Serverless Inference** for spiky traffic.\n",
    "- **Safety**: roll out with **canary**/**blue‑green** and a **bake period**; keep rollback script handy.\n",
    "- **Cost control**: right‑size instances; use serverless for intermittent traffic; clean up test endpoints.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
